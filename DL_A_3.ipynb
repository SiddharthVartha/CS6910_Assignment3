{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "1qnQorOWhwyf"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "MNknYo2IfkCc"
      },
      "outputs": [],
      "source": [
        "def read_and_split_data(train_file, test_file, val_file):\n",
        "    # Read data\n",
        "    train_data = pd.read_csv(train_file, header=None)\n",
        "    test_data = pd.read_csv(test_file, header=None)\n",
        "    val_data = pd.read_csv(val_file, header=None)\n",
        "\n",
        "    # Split into English and Marathi words\n",
        "    english_train = train_data.iloc[:, 0]\n",
        "    marathi_train = train_data.iloc[:, 1]\n",
        "\n",
        "    english_test = test_data.iloc[:, 0]\n",
        "    marathi_test = test_data.iloc[:, 1]\n",
        "\n",
        "    english_val = val_data.iloc[:, 0]\n",
        "    marathi_val = val_data.iloc[:, 1]\n",
        "\n",
        "    return (english_train, marathi_train, english_test, marathi_test, english_val, marathi_val)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "m6z-uILhfJ5h"
      },
      "outputs": [],
      "source": [
        "# File paths\n",
        "lang=\"mar\"\n",
        "train_file = f\"/content/drive/MyDrive/DeepLearning/aksharantar_sampled/{lang}/{lang}_train.csv\"\n",
        "test_file = f\"/content/drive/MyDrive/DeepLearning/aksharantar_sampled/{lang}/{lang}_test.csv\"\n",
        "val_file = f\"/content/drive/MyDrive/DeepLearning/aksharantar_sampled/{lang}/{lang}_valid.csv\"\n",
        "\n",
        "# Call the function\n",
        "english_train, marathi_train, english_test, marathi_test, english_val, marathi_val = read_and_split_data(train_file, test_file, val_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "RbF5_Ta7grGl"
      },
      "outputs": [],
      "source": [
        "def create_char_list(words):\n",
        "    char_set = set(char for word in words for char in word)\n",
        "    char_list = sorted(char_set)\n",
        "    max_length_word = max(len(word) for word in words)\n",
        "    return char_list, max_length_word\n",
        "\n",
        "\n",
        "def find_max_length(word_list):\n",
        "    max_length = -1\n",
        "    for word in word_list:\n",
        "        max_length = max(max_length, len(word))\n",
        "    return max_length\n",
        "\n",
        "# Create character lists and find maximum word lengths\n",
        "english_chars, english_max_len = create_char_list(english_train)\n",
        "marathi_chars, marathi_max_len = create_char_list(marathi_train)\n",
        "\n",
        "# Find maximum word lengths from validation and test data\n",
        "english_max_len = max(find_max_length(english_val), find_max_length(english_test), english_max_len)\n",
        "marathi_max_len = max(find_max_length(marathi_val), find_max_length(marathi_test), marathi_max_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "FL9AwUVghDu-"
      },
      "outputs": [],
      "source": [
        "def word_to_vector(word, lang):\n",
        "    max_len = -1\n",
        "    if lang == \"english\":\n",
        "        max_len = english_max_len\n",
        "    else:\n",
        "        max_len = marathi_max_len\n",
        "\n",
        "    vector = [0] * (max_len + 2)  # Initialize vector with max length + 2 (for special tokens)\n",
        "    vector[0] = len(english_chars) + 1 if lang == \"english\" else len(marathi_chars) + 1\n",
        "    count=1\n",
        "    if(lang == \"english\"):\n",
        "        for char in word:\n",
        "            for i in range(len(english_chars)):\n",
        "                if(english_chars[i] == char):\n",
        "                    vector[count]=i+1\n",
        "                    count+=1\n",
        "    else :\n",
        "        for char in word:\n",
        "            for i in range(len(marathi_chars)):\n",
        "                if(marathi_chars[i] == char):\n",
        "                    vector[count]=i+1\n",
        "                    count+=1\n",
        "\n",
        "    return vector\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xeJ3-BojJXL",
        "outputId": "d8011280-d7d7-4412-e91e-786e751a79e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "रुद्रांची\n"
          ]
        }
      ],
      "source": [
        "print(marathi_train[13])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "qigC8n59hMVu"
      },
      "outputs": [],
      "source": [
        "vec = word_to_vector(marathi_train[13],\"marathi\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VaAzzdb-kriV",
        "outputId": "3c69a555-d995-4b2c-fdbb-678ed2bfba42"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[64, 42, 54, 33, 63, 42, 51, 2, 21, 53, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "25npFzyMlN9F"
      },
      "outputs": [],
      "source": [
        "# creating matrix of representation\n",
        "def word_matrix(words, language):\n",
        "    matrix = []\n",
        "    for word in words:\n",
        "        matrix.append(word_to_vector(word, language))\n",
        "    return torch.tensor(matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "H_a5L2zIltAN"
      },
      "outputs": [],
      "source": [
        "def prepare_word_matrices(train_data, val_data, test_data, language):\n",
        "    train_matrix = word_matrix(train_data, language)\n",
        "    val_matrix = word_matrix(val_data, language)\n",
        "    test_matrix = word_matrix(test_data, language)\n",
        "    return train_matrix, val_matrix, test_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "8ldk0JNTl24R"
      },
      "outputs": [],
      "source": [
        "english_matrix, english_matrix_val, english_matrix_test = prepare_word_matrices(english_train, english_val, english_test, \"english\")\n",
        "marathi_matrix, marathi_matrix_val, marathi_matrix_test = prepare_word_matrices(marathi_train, marathi_val, marathi_test, \"marathi\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_size, embedding_dim, hidden_size, num_layers, batch_size, dropout_prob, bidirectional, cell_type):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.batch_size = batch_size\n",
        "        self.dropout = nn.Dropout(dropout_prob)\n",
        "        self.biderectional = bidirectional\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.embedding = nn.Embedding(input_size, embedding_dim)\n",
        "        self.cell_type = cell_type\n",
        "\n",
        "        rnn_class = nn.RNN if cell_type == \"RNN\" else (nn.LSTM if cell_type == \"LSTM\" else nn.GRU)\n",
        "        self.rnn = rnn_class(embedding_dim, hidden_size, num_layers, dropout=dropout_prob, bidirectional=bidirectional)\n",
        "\n",
        "    def forward(self, input):\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        if self.cell_type == \"LSTM\":\n",
        "            output, (hidden, cell) = self.rnn(embedded)\n",
        "        else:\n",
        "            output, hidden = self.rnn(embedded)\n",
        "\n",
        "        return (output, hidden, cell) if self.cell_type == \"LSTM\" else (output, hidden)\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "metadata": {
        "id": "p-DiYudYZwAF"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, input_size, embedding_size, hidden_size, output_size, dec_layers, p, cell_type, attention=False, bidirectional=False):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dec_layers = dec_layers\n",
        "        self.dropout = nn.Dropout(p)\n",
        "        self.cell_type = cell_type\n",
        "        self.attention = attention\n",
        "        self.bidirectional = bidirectional\n",
        "        self.max_length = len(english_matrix[0])\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
        "        rnn_input_size = hidden_size if attention else embedding_size\n",
        "        rnn_class = nn.RNN if cell_type == \"RNN\" else (nn.LSTM if cell_type == \"LSTM\" else nn.GRU)\n",
        "        self.rnn = rnn_class(rnn_input_size, hidden_size, dec_layers, dropout=p)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "        if attention:\n",
        "            self.attn = nn.Linear(hidden_size + embedding_size, self.max_length)\n",
        "            self.attn_combine = nn.Linear(hidden_size * 2 + embedding_size, hidden_size) if bidirectional else nn.Linear(hidden_size + embedding_size, hidden_size)\n",
        "\n",
        "    def forward(self, x, output, hidden, cell=None):\n",
        "        x = x.unsqueeze(0)\n",
        "        embedded = self.embedding(x)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        if self.attention:\n",
        "            attn_weights = F.softmax(self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "            attn_applied = torch.bmm(attn_weights.unsqueeze(1), output.permute(1, 0, 2)).squeeze(1)\n",
        "            op = torch.cat((embedded[0], attn_applied), 1)\n",
        "            op = self.attn_combine(op).unsqueeze(0)\n",
        "            op = F.relu(op)\n",
        "        else:\n",
        "            op = embedded\n",
        "\n",
        "        if self.cell_type == \"LSTM\":\n",
        "            outputs, (hidden, cell) = self.rnn(op, (hidden, cell))\n",
        "        else:\n",
        "            outputs, hidden = self.rnn(op, hidden)\n",
        "\n",
        "        predictions, hidden, cell = self.generate_predictions(outputs, hidden, cell)\n",
        "\n",
        "        return predictions, hidden, cell\n",
        "\n",
        "    def generate_predictions(self, rnn_outputs, rnn_hidden, rnn_cell=None):\n",
        "        output_predictions = self.fc(rnn_outputs)\n",
        "        output_predictions = output_predictions.squeeze(0)\n",
        "\n",
        "        return (output_predictions, rnn_hidden, rnn_cell) if self.cell_type == \"LSTM\" else (output_predictions, rnn_hidden ,rnn_cell)\n",
        "\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)\n"
      ],
      "metadata": {
        "id": "kU8laIvE1C_v"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2SeqModel(nn.Module):\n",
        "    def __init__(self, output_size, cell_type, bidirectional, enc_layers, dec_layers, encoder, decoder):\n",
        "        super(Seq2SeqModel, self).__init__()\n",
        "        self.output_size = output_size\n",
        "        self.cell_type = cell_type\n",
        "        self.bidirectional = bidirectional\n",
        "        self.enc_layers = enc_layers\n",
        "        self.dec_layers = dec_layers\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, source, target , teacher_force_ratio=0.5):\n",
        "        target_len = target.shape[0]\n",
        "        batch_size = source.shape[1]\n",
        "\n",
        "        outputs = torch.zeros(target_len, batch_size, self.output_size).to(source.device)\n",
        "\n",
        "        encoder_output, hidden, cell = self.encode_sequence(source)\n",
        "        hidden, cell = self.prepare_decoder_states(hidden, cell)\n",
        "        outputs = self.decode_sequence(target, encoder_output, hidden, cell, teacher_force_ratio)\n",
        "\n",
        "        return outputs\n",
        "\n",
        "    def encode_sequence(self, source):\n",
        "        if self.cell_type == \"LSTM\":\n",
        "            encoder_output, hidden, cell = self.encoder(source)\n",
        "            return encoder_output, hidden, cell\n",
        "        else:\n",
        "            encoder_output, hidden = self.encoder(source)\n",
        "            return encoder_output, hidden, None\n",
        "\n",
        "    def prepare_decoder_states(self, hidden, cell):\n",
        "        if self.bidirectional or self.enc_layers != self.dec_layers:\n",
        "          hidden = hidden[self.enc_layers - 1] + hidden[self.enc_layers - 1]\n",
        "          hidden = hidden.repeat(self.dec_layers,1,1)\n",
        "          if(self.cell_type == \"LSTM\"):\n",
        "              cell = cell[self.enc_layers - 1] + cell[self.enc_layers - 1]\n",
        "              cell = cell.repeat(self.dec_layers,1,1)\n",
        "        return hidden, cell\n",
        "\n",
        "\n",
        "    def decode_sequence(self, tgt, enc_out, hid, cell, teacher_force_ratio):\n",
        "        batch_size = tgt.shape[1]\n",
        "        target_len = tgt.shape[0]\n",
        "        outputs = torch.zeros(target_len, batch_size, self.output_size).to(enc_out.device)\n",
        "\n",
        "        timestep = 1\n",
        "        current_token = tgt[0]\n",
        "\n",
        "        while timestep < target_len:\n",
        "            if self.cell_type == \"LSTM\":\n",
        "                output, hid, cell = self.decoder(current_token, enc_out, hid, cell)\n",
        "            else:\n",
        "                output, hid, cell = self.decoder(current_token, enc_out, hid)\n",
        "            outputs[timestep] = output\n",
        "\n",
        "            if random.random() < teacher_force_ratio:\n",
        "                current_token = tgt[timestep] if timestep < target_len - 1 else output.argmax(1)\n",
        "            else:\n",
        "                current_token = output.argmax(1)\n",
        "\n",
        "            timestep += 1\n",
        "\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "5xY9str_1F2E"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_accuracy(model, input_data, target_data, batch_size):\n",
        "    correct_count = 0\n",
        "    total_samples = len(input_data)\n",
        "    for idx in range(0, total_samples, batch_size):\n",
        "        input_batch = input_data[idx:idx + batch_size].to(device)\n",
        "        target_batch = target_data[idx:idx + batch_size].to(device)\n",
        "\n",
        "        output = model(input_batch.T, target_batch.T, teacher_force_ratio=0)\n",
        "        predicted_tokens = torch.argmax(F.softmax(output, dim=2), dim=2).T\n",
        "\n",
        "        correct_count += torch.all(predicted_tokens[:, 1:] == target_batch[:, 1:], dim=1).sum().item()\n",
        "\n",
        "    accuracy = correct_count * 100 / total_samples\n",
        "    return accuracy\n"
      ],
      "metadata": {
        "id": "WBIL7mwf1TVq"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(epochs, learning_rate, cell_type, bidirectional, enc_layers, dec_layers, batch_size, embedding_dim, hidden_size, enc_dropout, dec_dropout,attention):\n",
        "    pad_idx = len(marathi_chars) + 1\n",
        "\n",
        "    input_size_encoder = len(english_chars)\n",
        "    input_size_decoder = len(marathi_chars)\n",
        "    output_size = len(marathi_chars)\n",
        "    input_size_encoder+=2\n",
        "    input_size_decoder+=2\n",
        "    output_size+=2\n",
        "\n",
        "    encoder = Encoder(input_size_encoder, embedding_dim, hidden_size, enc_layers,batch_size, enc_dropout,bidirectional, cell_type).to(device)\n",
        "    decoder= Decoder(input_size_decoder,embedding_dim,hidden_size,output_size,dec_layers,dec_dropout, cell_type,attention,bidirectional).to(device)\n",
        "\n",
        "    model = Seq2SeqModel(output_size, cell_type, bidirectional, enc_layers, dec_layers ,encoder, decoder).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print(\"Epoch: \", epoch+1)\n",
        "\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        val_loss = 0\n",
        "        step = 0\n",
        "        total_batches = len(english_matrix) // batch_size\n",
        "\n",
        "        for batch_idx in tqdm(range(total_batches)):\n",
        "            start_idx = batch_size * batch_idx\n",
        "            end_idx = batch_size * (batch_idx + 1)\n",
        "\n",
        "            inp_data = english_matrix[start_idx:end_idx].to(device)\n",
        "            target = marathi_matrix[start_idx:end_idx].to(device)\n",
        "            target = target.T\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output = model(inp_data.T, target)\n",
        "\n",
        "            output = output[1:].reshape(-1, output.shape[2])\n",
        "            target = target[1:].reshape(-1)\n",
        "\n",
        "            loss = criterion(output, target)\n",
        "            total_loss += loss.item()\n",
        "            loss.backward()\n",
        "\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            step += 1\n",
        "\n",
        "        with torch.no_grad():\n",
        "            model.eval()\n",
        "            val_batches = len(english_matrix_val) // batch_size\n",
        "            for val_batch_idx in range(val_batches):\n",
        "                val_start_idx = batch_size * val_batch_idx\n",
        "                val_end_idx = batch_size * (val_batch_idx + 1)\n",
        "\n",
        "                val_inp_data = english_matrix_val[val_start_idx:val_end_idx].to(device)\n",
        "                val_target = marathi_matrix_val[val_start_idx:val_end_idx].to(device)\n",
        "                val_target = val_target.T\n",
        "\n",
        "                val_output = model(val_inp_data.T, val_target)\n",
        "                val_output = val_output[1:].reshape(-1, val_output.shape[2])\n",
        "                val_target = val_target[1:].reshape(-1)\n",
        "\n",
        "                val_loss += criterion(val_output, val_target).item()\n",
        "\n",
        "            val_loss /= val_batches\n",
        "        training_accuracy = calculate_accuracy(model, english_matrix, marathi_matrix, batch_size)\n",
        "        val_accuracy = calculate_accuracy(model, english_matrix_val, marathi_matrix_val, batch_size)\n",
        "\n",
        "        print(f\"Loss: {total_loss/step}\\t Accuracy: {training_accuracy}\\t Val_Accuracy: {val_accuracy}\\t Val_Loss: {val_loss}\")"
      ],
      "metadata": {
        "id": "hx8anR1Q1Kai"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "learning_rate = 1e-3\n",
        "cell_type = \"GRU\"\n",
        "bidirectional = False\n",
        "enc_layers = 4\n",
        "dec_layers = 3\n",
        "batch_size = 256\n",
        "embedding_dim = 384\n",
        "hidden_size = 384\n",
        "enc_dropout =  0.2\n",
        "dec_dropout = 0\n",
        "attention = False\n",
        "\n",
        "train_model(epochs, learning_rate, cell_type, bidirectional, enc_layers,\n",
        "            dec_layers, batch_size, embedding_dim, hidden_size, enc_dropout, dec_dropout, attention)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cg39Syx1ZDj",
        "outputId": "7ed4647b-0856-4762-c0fb-cf18458ea2bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [18:15<00:00,  5.48s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 1.3061532968282699\t Accuracy: 2.853515625\t Val_Accuracy: 6.5673828125\t Val_Loss: 0.5627245604991913\n",
            "Epoch:  2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 40/200 [03:39<14:53,  5.58s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hHOsBfjC1dAR"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1LgxO2cJI45RCxPsXLWbREo0DatxfZuGr",
      "authorship_tag": "ABX9TyOrRzHBb0JNJwim76TM6wEo"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}