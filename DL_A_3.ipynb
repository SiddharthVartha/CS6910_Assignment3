{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8375982,"sourceType":"datasetVersion","datasetId":4980280},{"sourceId":8412111,"sourceType":"datasetVersion","datasetId":5006779}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#!pip install wandb\nimport numpy as np\nimport pandas as pd\nimport wandb\nimport random\nimport torch\nimport torch.nn as nn\nfrom torch import optim\nimport matplotlib.pyplot as plt\nfrom matplotlib import font_manager as fm\nimport torch.nn.functional as F\nfrom tqdm import tqdm\nwandb.login()\nimport csv\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-15T18:07:53.309860Z","iopub.execute_input":"2024-05-15T18:07:53.310473Z","iopub.status.idle":"2024-05-15T18:08:09.721761Z","shell.execute_reply.started":"2024-05-15T18:07:53.310438Z","shell.execute_reply":"2024-05-15T18:08:09.720973Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"}]},{"cell_type":"code","source":"def read_and_split_data(train_file, test_file, val_file):\n    # Read data\n    train_data = pd.read_csv(train_file, header=None)\n    test_data = pd.read_csv(test_file, header=None)\n    val_data = pd.read_csv(val_file, header=None)\n\n    # Split into English and Marathi words\n    english_train = train_data.iloc[:, 0]\n    marathi_train = train_data.iloc[:, 1]\n\n    english_test = test_data.iloc[:, 0]\n    marathi_test = test_data.iloc[:, 1]\n\n    english_val = val_data.iloc[:, 0]\n    marathi_val = val_data.iloc[:, 1]\n\n    return (english_train, marathi_train, english_test, marathi_test, english_val, marathi_val)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-05-15T18:26:53.912271Z","iopub.execute_input":"2024-05-15T18:26:53.912636Z","iopub.status.idle":"2024-05-15T18:26:53.920059Z","shell.execute_reply.started":"2024-05-15T18:26:53.912605Z","shell.execute_reply":"2024-05-15T18:26:53.918898Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# File paths\nlang=\"mar\"\ntrain_file = f\"/kaggle/input/aksharantar-sampled/aksharantar_sampled/{lang}/{lang}_train.csv\"\ntest_file = f\"/kaggle/input/aksharantar-sampled/aksharantar_sampled/{lang}/{lang}_test.csv\"\nval_file = f\"/kaggle/input/aksharantar-sampled/aksharantar_sampled/{lang}/{lang}_valid.csv\"\n\n# Call the function\nenglish_train, marathi_train, english_test, marathi_test, english_val, marathi_val = read_and_split_data(train_file, test_file, val_file)","metadata":{"execution":{"iopub.status.busy":"2024-05-15T18:26:54.148010Z","iopub.execute_input":"2024-05-15T18:26:54.148306Z","iopub.status.idle":"2024-05-15T18:26:54.268386Z","shell.execute_reply.started":"2024-05-15T18:26:54.148280Z","shell.execute_reply":"2024-05-15T18:26:54.267636Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def create_char_list(words):\n    char_set = set(char for word in words for char in word)\n    char_list = sorted(char_set)\n    max_length_word = max(len(word) for word in words)\n    return char_list, max_length_word\n\n\ndef find_max_length(word_list):\n    max_length = -1\n    for word in word_list:\n        max_length = max(max_length, len(word))\n    return max_length\n\n# Create character lists and find maximum word lengths\nenglish_chars, english_max_len = create_char_list(english_train)\nmarathi_chars, marathi_max_len = create_char_list(marathi_train)\n\n# Find maximum word lengths from validation and test data\nenglish_max_len = max(find_max_length(english_val), find_max_length(english_test), english_max_len)\nmarathi_max_len = max(find_max_length(marathi_val), find_max_length(marathi_test), marathi_max_len)","metadata":{"execution":{"iopub.status.busy":"2024-05-15T18:26:54.366191Z","iopub.execute_input":"2024-05-15T18:26:54.366481Z","iopub.status.idle":"2024-05-15T18:26:54.501059Z","shell.execute_reply.started":"2024-05-15T18:26:54.366456Z","shell.execute_reply":"2024-05-15T18:26:54.500362Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"def word_to_vector(word, lang):\n    max_len = -1\n    if lang == \"english\":\n        max_len = english_max_len\n    else:\n        max_len = marathi_max_len\n\n    vector = [0] * (max_len + 2)  # Initialize vector with max length + 2 (for special tokens)\n    vector[0] = len(english_chars) + 1 if lang == \"english\" else len(marathi_chars) + 1\n    count=1\n    if(lang == \"english\"):\n        for char in word:\n            for i in range(len(english_chars)):\n                if(english_chars[i] == char):\n                    vector[count]=i+1\n                    count+=1\n    else :\n        for char in word:\n            for i in range(len(marathi_chars)):\n                if(marathi_chars[i] == char):\n                    vector[count]=i+1\n                    count+=1\n\n    return vector\n","metadata":{"execution":{"iopub.status.busy":"2024-05-15T18:26:54.567164Z","iopub.execute_input":"2024-05-15T18:26:54.567437Z","iopub.status.idle":"2024-05-15T18:26:54.575162Z","shell.execute_reply.started":"2024-05-15T18:26:54.567413Z","shell.execute_reply":"2024-05-15T18:26:54.574185Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"def indices_to_words(indices, language):\n    words = []\n    char_list = english_chars if language == \"english\" else marathi_chars\n    for idx in range(len(indices)):\n        if idx == 0:\n            continue\n        if indices[idx]==0:\n            break\n        char = char_list[indices[idx] - 1]  # Adjust for zero-indexing\n        words.append(char)\n    return ''.join(words)","metadata":{"execution":{"iopub.status.busy":"2024-05-15T18:26:54.807940Z","iopub.execute_input":"2024-05-15T18:26:54.808288Z","iopub.status.idle":"2024-05-15T18:26:54.813813Z","shell.execute_reply.started":"2024-05-15T18:26:54.808257Z","shell.execute_reply":"2024-05-15T18:26:54.812893Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# creating matrix of representation\ndef word_matrix(words, language):\n    matrix = []\n    for word in words:\n        matrix.append(word_to_vector(word, language))\n    return torch.tensor(matrix)","metadata":{"execution":{"iopub.status.busy":"2024-05-15T18:26:55.033407Z","iopub.execute_input":"2024-05-15T18:26:55.033706Z","iopub.status.idle":"2024-05-15T18:26:55.038598Z","shell.execute_reply.started":"2024-05-15T18:26:55.033680Z","shell.execute_reply":"2024-05-15T18:26:55.037613Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"def prepare_word_matrices(train_data, val_data, test_data, language):\n    train_matrix = word_matrix(train_data, language)\n    val_matrix = word_matrix(val_data, language)\n    test_matrix = word_matrix(test_data, language)\n    return train_matrix, val_matrix, test_matrix","metadata":{"execution":{"iopub.status.busy":"2024-05-15T18:26:55.290528Z","iopub.execute_input":"2024-05-15T18:26:55.290931Z","iopub.status.idle":"2024-05-15T18:26:55.295691Z","shell.execute_reply.started":"2024-05-15T18:26:55.290905Z","shell.execute_reply":"2024-05-15T18:26:55.294811Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"english_matrix, english_matrix_val, english_matrix_test = prepare_word_matrices(english_train, english_val, english_test, \"english\")\nmarathi_matrix, marathi_matrix_val, marathi_matrix_test = prepare_word_matrices(marathi_train, marathi_val, marathi_test, \"marathi\")","metadata":{"execution":{"iopub.status.busy":"2024-05-15T18:26:55.666571Z","iopub.execute_input":"2024-05-15T18:26:55.666879Z","iopub.status.idle":"2024-05-15T18:27:03.134668Z","shell.execute_reply.started":"2024-05-15T18:26:55.666853Z","shell.execute_reply":"2024-05-15T18:27:03.133577Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"class Encoder(nn.Module):\n    def __init__(self, input_size, embedding_dim, hidden_size, num_layers, batch_size, dropout_prob, bidirectional, cell_type):\n        super(Encoder, self).__init__()\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        self.batch_size = batch_size\n        self.dropout = nn.Dropout(dropout_prob)\n        self.biderectional = bidirectional\n        self.embedding_dim = embedding_dim\n        self.embedding = nn.Embedding(input_size, embedding_dim)\n        self.cell_type = cell_type\n\n        rnn_class = nn.RNN if cell_type == \"RNN\" else (nn.LSTM if cell_type == \"LSTM\" else nn.GRU)\n        self.rnn = rnn_class(embedding_dim, hidden_size, num_layers, dropout=dropout_prob, bidirectional=bidirectional)\n\n    def forward(self, input):\n        embedded = self.dropout(self.embedding(input))\n        if self.cell_type == \"LSTM\":\n            output, (hidden, cell) = self.rnn(embedded)\n        else:\n            output, hidden = self.rnn(embedded)\n\n        return (output, hidden, cell) if self.cell_type == \"LSTM\" else (output, hidden)\n\n    def init_hidden(self):\n        return torch.zeros(1, 1, self.hidden_size, device=device)","metadata":{"execution":{"iopub.status.busy":"2024-05-15T18:27:03.136453Z","iopub.execute_input":"2024-05-15T18:27:03.136747Z","iopub.status.idle":"2024-05-15T18:27:03.147321Z","shell.execute_reply.started":"2024-05-15T18:27:03.136721Z","shell.execute_reply":"2024-05-15T18:27:03.145892Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"class Decoder(nn.Module):\n    def __init__(self, input_size, embedding_size, hidden_size, output_size, dec_layers, p, cell_type, attention=False, bidirectional=False):\n        super(Decoder, self).__init__()\n        self.hidden_size = hidden_size\n        self.output_size = output_size\n        self.dec_layers = dec_layers\n        self.dropout = nn.Dropout(p)\n        self.cell_type = cell_type\n        self.attention = attention\n        self.bidirectional = bidirectional\n        self.max_length = len(english_matrix[0])\n        self.attn_weights=0\n\n        self.embedding = nn.Embedding(input_size, embedding_size)\n        rnn_input_size = hidden_size if attention else embedding_size\n        rnn_class = nn.RNN if cell_type == \"RNN\" else (nn.LSTM if cell_type == \"LSTM\" else nn.GRU)\n        self.rnn = rnn_class(rnn_input_size, hidden_size, dec_layers, dropout=p)\n        self.fc = nn.Linear(hidden_size, output_size)\n\n        if attention:\n            self.attn = nn.Linear(hidden_size + embedding_size, self.max_length)\n            self.attn_combine = nn.Linear(hidden_size * 2 + embedding_size, hidden_size) if bidirectional else nn.Linear(hidden_size + embedding_size, hidden_size)\n\n    def forward(self, x, output, hidden, cell=None):\n      x = x.unsqueeze(0)\n      embedded = self.embedding(x)\n      embedded = self.dropout(embedded)\n\n      if self.attention:\n          attn_weights = F.softmax(self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n          self.attn_weights = attn_weights  # Store attention weights\n          attn_applied = torch.bmm(attn_weights.unsqueeze(1), output.permute(1, 0, 2)).squeeze(1)\n          op = torch.cat((embedded[0], attn_applied), 1)\n          op = self.attn_combine(op).unsqueeze(0)\n          op = F.relu(op)\n      else:\n          op = embedded\n\n      if self.cell_type == \"LSTM\":\n          outputs, (hidden, cell) = self.rnn(op, (hidden, cell))\n      else:\n          outputs, hidden = self.rnn(op, hidden)\n\n      predictions, hidden, cell = self.generate_predictions(outputs, hidden, cell)\n\n      return predictions, hidden, cell\n\n\n    def generate_predictions(self, rnn_outputs, rnn_hidden, rnn_cell=None):\n        output_predictions = self.fc(rnn_outputs)\n        output_predictions = output_predictions.squeeze(0)\n\n        return (output_predictions, rnn_hidden, rnn_cell) if self.cell_type == \"LSTM\" else (output_predictions, rnn_hidden ,rnn_cell)\n\n\n    def initHidden(self):\n        return torch.zeros(1, 1, self.hidden_size, device=device)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-15T18:27:03.148604Z","iopub.execute_input":"2024-05-15T18:27:03.148950Z","iopub.status.idle":"2024-05-15T18:27:03.167210Z","shell.execute_reply.started":"2024-05-15T18:27:03.148917Z","shell.execute_reply":"2024-05-15T18:27:03.166171Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"class Seq2SeqModel(nn.Module):\n    def __init__(self, output_size, cell_type, bidirectional, enc_layers, dec_layers, encoder, decoder,attention):\n        super(Seq2SeqModel, self).__init__()\n        self.output_size = output_size\n        self.cell_type = cell_type\n        self.bidirectional = bidirectional\n        self.enc_layers = enc_layers\n        self.dec_layers = dec_layers\n        self.encoder = encoder\n        self.attention=attention\n        self.decoder = decoder\n\n    def forward(self, source, target , teacher_force_ratio=0.5):\n        target_len = target.shape[0]\n        batch_size = source.shape[1]\n\n        outputs = torch.zeros(target_len, batch_size, self.output_size).to(source.device)\n\n        encoder_output, hidden, cell = self.encode_sequence(source)\n        hidden, cell = self.prepare_decoder_states(hidden, cell)\n        outputs,attentions = self.decode_sequence(target, encoder_output, hidden, cell, teacher_force_ratio)\n\n        return outputs,attentions\n\n    def encode_sequence(self, source):\n        if self.cell_type == \"LSTM\":\n            encoder_output, hidden, cell = self.encoder(source)\n            return encoder_output, hidden, cell\n        else:\n            encoder_output, hidden = self.encoder(source)\n            return encoder_output, hidden, None\n\n    def prepare_decoder_states(self, hidden, cell):\n        if self.bidirectional or self.enc_layers != self.dec_layers:\n          hidden = hidden[self.enc_layers - 1] + hidden[self.enc_layers - 1]\n          hidden = hidden.repeat(self.dec_layers,1,1)\n          if(self.cell_type == \"LSTM\"):\n              cell = cell[self.enc_layers - 1] + cell[self.enc_layers - 1]\n              cell = cell.repeat(self.dec_layers,1,1)\n        return hidden, cell\n\n\n    def decode_sequence(self, tgt, enc_out, hid, cell, teacher_force_ratio):\n      batch_size = tgt.shape[1]\n      target_len = tgt.shape[0]\n      outputs = torch.zeros(target_len, batch_size, self.output_size).to(enc_out.device)\n      attentions = []\n\n      timestep = 1\n      current_token = tgt[0]\n\n      while timestep < target_len:\n          if self.cell_type == \"LSTM\":\n              output, hid, cell = self.decoder(current_token, enc_out, hid, cell)\n          else:\n              output, hid, cell = self.decoder(current_token, enc_out, hid)\n          outputs[timestep] = output\n\n          if(self.attention==True):\n            attentions.append(self.decoder.attn_weights.detach().cpu().numpy())\n\n          if random.random() < teacher_force_ratio:\n              current_token = tgt[timestep] if timestep < target_len - 1 else output.argmax(1)\n          else:\n              current_token = output.argmax(1)\n\n          timestep += 1\n\n      attentions = np.array(attentions)\n      return outputs, attentions\n","metadata":{"execution":{"iopub.status.busy":"2024-05-15T18:27:03.169865Z","iopub.execute_input":"2024-05-15T18:27:03.170465Z","iopub.status.idle":"2024-05-15T18:27:03.186753Z","shell.execute_reply.started":"2024-05-15T18:27:03.170438Z","shell.execute_reply":"2024-05-15T18:27:03.185673Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"def calculate_accuracy_test(model, input_data, target_data, batch_size):\n    correct_count = 0\n    total_samples = len(input_data)\n    predicted_words=[]\n    attention_list=[np.random.rand(10, 10)]\n    for idx in range(0, total_samples, batch_size):\n        input_batch = input_data[idx:idx + batch_size].to(device)\n        target_batch = target_data[idx:idx + batch_size].to(device)\n\n        output,attentions = model(input_batch.T, target_batch.T, teacher_force_ratio=0)\n        if idx==0:\n          attention_list[0]=attentions\n        predicted_tokens = torch.argmax(F.softmax(output, dim=2), dim=2).T\n        \n        for tokens in predicted_tokens:\n            predicted_word = indices_to_words(tokens, \"marathi\")\n            predicted_words.append(predicted_word)\n            \n        correct_count += torch.all(predicted_tokens[:, 1:] == target_batch[:, 1:], dim=1).sum().item()\n        \n    accuracy = correct_count * 100 / total_samples\n    return accuracy,predicted_words,attention_list\n","metadata":{"execution":{"iopub.status.busy":"2024-05-15T18:27:03.187904Z","iopub.execute_input":"2024-05-15T18:27:03.188250Z","iopub.status.idle":"2024-05-15T18:27:03.200215Z","shell.execute_reply.started":"2024-05-15T18:27:03.188214Z","shell.execute_reply":"2024-05-15T18:27:03.199318Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"def calculate_accuracy(model, input_data, target_data, batch_size):\n    correct_count = 0\n    total_samples = len(input_data)\n    for idx in range(0, total_samples, batch_size):\n        input_batch = input_data[idx:idx + batch_size].to(device)\n        target_batch = target_data[idx:idx + batch_size].to(device)\n\n        output,attentions = model(input_batch.T, target_batch.T, teacher_force_ratio=0)\n        predicted_tokens = torch.argmax(F.softmax(output, dim=2), dim=2).T\n\n        correct_count += torch.all(predicted_tokens[:, 1:] == target_batch[:, 1:], dim=1).sum().item()\n\n    accuracy = correct_count * 100 / total_samples\n    return accuracy\n","metadata":{"execution":{"iopub.status.busy":"2024-05-15T18:27:03.201414Z","iopub.execute_input":"2024-05-15T18:27:03.201761Z","iopub.status.idle":"2024-05-15T18:27:03.209779Z","shell.execute_reply.started":"2024-05-15T18:27:03.201731Z","shell.execute_reply":"2024-05-15T18:27:03.209012Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"\ndef plot_attention_heatmap_grid(actual_words, predicted_words, attention_weights_list):\n    num_plots = min(len(actual_words), 9)  # Limit to 9 plots for a 3x3 grid\n    num_rows = 3\n    num_cols = 3\n\n    fig, axes = plt.subplots(num_rows, num_cols, figsize=(20, 20))\n\n    # Load custom font\n    prop = fm.FontProperties(fname=\"/kaggle/input/marathi-text/Mukta-Regular.ttf\")\n\n    for i in range(num_plots):\n        row = i // num_cols\n        col = i % num_cols\n\n        actual_word = actual_words[i]\n        predicted_word = predicted_words[i]\n        attention_weights = attention_weights_list[i]\n        print(actual_word,predicted_word)\n        actual_len = len(actual_word)\n        predicted_len = len(predicted_word)\n        heatmap_data = np.zeros((predicted_len, actual_len))\n\n        for j in range(predicted_len):\n            for k in range(actual_len):\n                heatmap_data[j][k] = attention_weights[j][k]\n\n        # Plot heatmap\n        im = axes[row, col].imshow(heatmap_data, cmap='viridis', aspect='auto')\n        cbar = fig.colorbar(im, ax=axes[row, col])  # Add color bar\n\n        # Set x and y tick labels with the custom font\n        axes[row, col].set_xticks(np.arange(len(actual_word)))\n        axes[row, col].set_yticks(np.arange(len(predicted_word)))\n        axes[row, col].set_xticklabels(list(actual_word), fontproperties=prop)\n        axes[row, col].set_yticklabels(list(predicted_word), fontproperties=prop)\n        \n        # Set title and labels\n        axes[row, col].set_title(f'Actual: {actual_word}\\nPredicted :{predicted_word}', fontproperties=prop, fontsize=22)\n        axes[row, col].set_xlabel('Actual', fontproperties=prop, fontsize=22)\n        axes[row, col].set_ylabel('Predicted', fontproperties=prop, fontsize=22)\n        axes[row, col].tick_params(axis='x', labelsize=22)\n        axes[row, col].tick_params(axis='y', labelsize=22)\n\n        # Adjust color bar font size\n        cbar.ax.tick_params(labelsize=18)\n\n    # Hide empty subplots if fewer than 9 examples\n    for i in range(num_plots, num_rows * num_cols):\n        row = i // num_cols\n        col = i % num_cols\n        axes[row, col].axis('off')\n\n    plt.tight_layout()\n    # Log to WandB\n    wandb.log({\"attention_heatmaps\": plt})\n    plt.show()\n\n","metadata":{"execution":{"iopub.status.busy":"2024-05-15T18:27:03.210905Z","iopub.execute_input":"2024-05-15T18:27:03.211178Z","iopub.status.idle":"2024-05-15T18:27:03.225813Z","shell.execute_reply.started":"2024-05-15T18:27:03.211149Z","shell.execute_reply":"2024-05-15T18:27:03.224884Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"def write_to_csv(actual_english, actual_marathi, predicted_marathi, filename):\n    with open(filename, mode='w', newline='', encoding='utf-8') as file:\n        writer = csv.writer(file)\n        writer.writerow(['Actual English', 'Actual Marathi', 'Predicted Marathi'])\n        for eng, mar_actual, mar_pred in zip(actual_english, actual_marathi, predicted_marathi):\n            writer.writerow([eng, mar_actual, mar_pred])\n","metadata":{"execution":{"iopub.status.busy":"2024-05-15T18:27:03.227040Z","iopub.execute_input":"2024-05-15T18:27:03.227308Z","iopub.status.idle":"2024-05-15T18:27:03.238823Z","shell.execute_reply.started":"2024-05-15T18:27:03.227284Z","shell.execute_reply":"2024-05-15T18:27:03.238065Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"def train_model(epochs, learning_rate, cell_type, bidirectional, enc_layers, dec_layers, batch_size, embedding_dim, hidden_size, enc_dropout, dec_dropout,attention):\n    pad_idx = len(marathi_chars) + 1\n    plot_heatmap=False\n    input_size_encoder = len(english_chars)\n    input_size_decoder = len(marathi_chars)\n    output_size = len(marathi_chars)\n    input_size_encoder+=2\n    input_size_decoder+=2\n    output_size+=2\n\n    encoder = Encoder(input_size_encoder, embedding_dim, hidden_size, enc_layers,batch_size, enc_dropout,bidirectional, cell_type).to(device)\n    decoder= Decoder(input_size_decoder,embedding_dim,hidden_size,output_size,dec_layers,dec_dropout, cell_type,attention,bidirectional).to(device)\n\n    model = Seq2SeqModel(output_size, cell_type, bidirectional, enc_layers, dec_layers ,encoder, decoder,attention).to(device)\n    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n    criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n    for epoch in range(epochs):\n        print(\"Epoch: \", epoch+1)\n\n        model.train()\n        total_loss = 0\n        val_loss = 0\n        step = 0\n        total_batches = len(english_matrix) // batch_size\n\n        for batch_idx in tqdm(range(total_batches)):\n            start_idx = batch_size * batch_idx\n            end_idx = batch_size * (batch_idx + 1)\n\n            inp_data = english_matrix[start_idx:end_idx].to(device)\n            target = marathi_matrix[start_idx:end_idx].to(device)\n            target = target.T\n\n            optimizer.zero_grad()\n            output, attentions = model(inp_data.T, target)\n            \n            output = output[1:].reshape(-1, output.shape[2])\n            target = target[1:].reshape(-1)\n\n            loss = criterion(output, target)\n            total_loss += loss.item()\n            loss.backward()\n\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n\n            optimizer.step()\n\n            step += 1\n\n        with torch.no_grad():\n            model.eval()\n            val_batches = len(english_matrix_val) // batch_size\n            for val_batch_idx in range(val_batches):\n                val_start_idx = batch_size * val_batch_idx\n                val_end_idx = batch_size * (val_batch_idx + 1)\n\n                val_inp_data = english_matrix_val[val_start_idx:val_end_idx].to(device)\n                val_target = marathi_matrix_val[val_start_idx:val_end_idx].to(device)\n                val_target = val_target.T\n\n                val_output,attentions = model(val_inp_data.T, val_target)\n                val_output = val_output[1:].reshape(-1, val_output.shape[2])\n                val_target = val_target[1:].reshape(-1)\n\n                val_loss += criterion(val_output, val_target).item()\n\n            val_loss /= val_batches\n        training_accuracy = calculate_accuracy(model, english_matrix, marathi_matrix, batch_size)\n        val_accuracy = calculate_accuracy(model, english_matrix_val, marathi_matrix_val, batch_size)\n      \n        wandb.log({\n           \"Epoch\": epoch+1,\n           \"Loss\": total_loss / step,\n           \"Accuracy\": training_accuracy,\n           \"Val_Accuracy\": val_accuracy,\n           \"Val_Loss\": val_loss\n        })\n        print(f\"Loss: {total_loss/step}\\t Accuracy: {training_accuracy}\\t Val_Accuracy: {val_accuracy}\\t Val_Loss: {val_loss}\")\n    test_accuracy,predicted_words,attention_list=calculate_accuracy_test(model, english_matrix_test, marathi_matrix_test, batch_size)\n    #write_to_csv(english_test, marathi_test, predicted_words, '/kaggle/working/predictions_vanilla.csv')\n    print(\"Test_Accuracy\",test_accuracy)\n    #wandb.log({'Test_Accuracy_Without_Attention':test_accuracy})\n    if(plot_heatmap==True):\n      plot_attention_heatmap_grid(marathi_test[:10], predicted_words[:10], attention_list[0][:10])","metadata":{"execution":{"iopub.status.busy":"2024-05-15T18:27:03.240053Z","iopub.execute_input":"2024-05-15T18:27:03.240346Z","iopub.status.idle":"2024-05-15T18:27:03.259077Z","shell.execute_reply.started":"2024-05-15T18:27:03.240322Z","shell.execute_reply":"2024-05-15T18:27:03.258238Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"# Define the sweep configuration\nsweep_config = {\n    \"method\": \"bayes\",\n    'metric': {\n        'name': 'Val_Accuracy',\n        'goal': 'maximize'\n    },\n    \"parameters\": {\n        \"epochs\": {\"values\": [ 10, 15 , 20]},  \n        \"learning_rate\": {\"values\": [1e-3, 1e-4]},\n        \"cell_type\": {\"values\": [\"RNN\",\"LSTM\", \"GRU\"]},\n        \"bidirectional\": {\"values\": [True, False]},\n        \"enc_layers\": {\"values\": [1, 2, 3, 4 ,5]},\n        \"dec_layers\": {\"values\": [1, 2, 3, 4 ,5]},\n        \"batch_size\": {\"values\": [128, 256, 512]},\n        \"embedding_dim\": {\"values\": [256, 384, 512]},\n        \"hidden_size\": {\"values\": [256, 384, 512]},\n        \"enc_dropout\": {\"values\": [0, 0.1, 0.2]},\n        \"dec_dropout\": {\"values\": [0, 0.1, 0.2]},\n        \"attention\": {\"values\": [False]}\n    }\n}","metadata":{"execution":{"iopub.status.busy":"2024-05-15T18:27:03.261709Z","iopub.execute_input":"2024-05-15T18:27:03.261993Z","iopub.status.idle":"2024-05-15T18:27:03.272850Z","shell.execute_reply.started":"2024-05-15T18:27:03.261966Z","shell.execute_reply":"2024-05-15T18:27:03.271823Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"def main():\n    # Initialize wandb\n    wandb.init()\n    config = wandb.config\n    wandb.run.name = \"_\".join([f\"{param}:{value}\" for param, value in config.items()])\n    train_model(**config)\n\n# Initialize the sweep\nsweep_id = wandb.sweep(sweep_config, project=\"deep_learn_assignment_3\",entity=\"cs23m063\")\n\n# Run the sweep\nwandb.agent(sweep_id, function=main,count=1)","metadata":{"execution":{"iopub.status.busy":"2024-05-15T18:27:03.274089Z","iopub.execute_input":"2024-05-15T18:27:03.274450Z","iopub.status.idle":"2024-05-15T18:53:25.097286Z","shell.execute_reply.started":"2024-05-15T18:27:03.274419Z","shell.execute_reply":"2024-05-15T18:53:25.096449Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"Create sweep with ID: 9b1cvoyg\nSweep URL: https://wandb.ai/cs23m063/deep_learn_assignment_3/sweeps/9b1cvoyg\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4tet7lum with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tattention: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 512\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_dropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_dim: 384\n\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_dropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 20\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 512\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240515_182706-4tet7lum</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs23m063/deep_learn_assignment_3/runs/4tet7lum' target=\"_blank\">skilled-sweep-1</a></strong> to <a href='https://wandb.ai/cs23m063/deep_learn_assignment_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs23m063/deep_learn_assignment_3/sweeps/9b1cvoyg' target=\"_blank\">https://wandb.ai/cs23m063/deep_learn_assignment_3/sweeps/9b1cvoyg</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs23m063/deep_learn_assignment_3' target=\"_blank\">https://wandb.ai/cs23m063/deep_learn_assignment_3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs23m063/deep_learn_assignment_3/sweeps/9b1cvoyg' target=\"_blank\">https://wandb.ai/cs23m063/deep_learn_assignment_3/sweeps/9b1cvoyg</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs23m063/deep_learn_assignment_3/runs/4tet7lum' target=\"_blank\">https://wandb.ai/cs23m063/deep_learn_assignment_3/runs/4tet7lum</a>"},"metadata":{}},{"name":"stdout","text":"Epoch:  1\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:57<00:00,  1.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.7470014250278474\t Accuracy: 0.0\t Val_Accuracy: 0.0244140625\t Val_Loss: 1.2255108058452606\nEpoch:  2\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:56<00:00,  1.77it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.4915192353725433\t Accuracy: 0.0\t Val_Accuracy: 0.0\t Val_Loss: 1.100884884595871\nEpoch:  3\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:56<00:00,  1.76it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.257953895330429\t Accuracy: 0.205078125\t Val_Accuracy: 0.68359375\t Val_Loss: 0.8222735747694969\nEpoch:  4\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:56<00:00,  1.76it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 0.8118593162298202\t Accuracy: 7.857421875\t Val_Accuracy: 10.64453125\t Val_Loss: 0.4390837550163269\nEpoch:  5\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:56<00:00,  1.76it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 0.531408383846283\t Accuracy: 17.76171875\t Val_Accuracy: 18.896484375\t Val_Loss: 0.37079978361725807\nEpoch:  6\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:56<00:00,  1.76it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 0.41040493696928027\t Accuracy: 26.76953125\t Val_Accuracy: 25.830078125\t Val_Loss: 0.34332484006881714\nEpoch:  7\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:57<00:00,  1.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 0.339615683555603\t Accuracy: 34.064453125\t Val_Accuracy: 31.396484375\t Val_Loss: 0.28310082107782364\nEpoch:  8\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:56<00:00,  1.76it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 0.2945192041993141\t Accuracy: 41.7265625\t Val_Accuracy: 35.546875\t Val_Loss: 0.23070906847715378\nEpoch:  9\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:57<00:00,  1.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 0.2561705146729946\t Accuracy: 47.130859375\t Val_Accuracy: 37.9638671875\t Val_Loss: 0.22521270252764225\nEpoch:  10\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:56<00:00,  1.76it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 0.23167430698871613\t Accuracy: 50.369140625\t Val_Accuracy: 39.35546875\t Val_Loss: 0.23837997764348984\nEpoch:  11\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:56<00:00,  1.76it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 0.20471431016921998\t Accuracy: 55.068359375\t Val_Accuracy: 39.599609375\t Val_Loss: 0.23173838667571545\nEpoch:  12\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:57<00:00,  1.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 0.18592539511620998\t Accuracy: 56.947265625\t Val_Accuracy: 40.283203125\t Val_Loss: 0.2214169278740883\nEpoch:  13\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:57<00:00,  1.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 0.1647955072671175\t Accuracy: 62.03125\t Val_Accuracy: 40.1611328125\t Val_Loss: 0.24688498117029667\nEpoch:  14\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:56<00:00,  1.76it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 0.15272942721843719\t Accuracy: 67.236328125\t Val_Accuracy: 43.5791015625\t Val_Loss: 0.22146608494222164\nEpoch:  15\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:57<00:00,  1.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 0.1400618761777878\t Accuracy: 67.984375\t Val_Accuracy: 42.919921875\t Val_Loss: 0.21810788102447987\nEpoch:  16\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:56<00:00,  1.76it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 0.13232398621737956\t Accuracy: 73.142578125\t Val_Accuracy: 44.2138671875\t Val_Loss: 0.23750203475356102\nEpoch:  17\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:57<00:00,  1.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 0.1165328136831522\t Accuracy: 76.79296875\t Val_Accuracy: 44.9951171875\t Val_Loss: 0.22560986503958702\nEpoch:  18\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:57<00:00,  1.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 0.10154804240912199\t Accuracy: 80.140625\t Val_Accuracy: 44.921875\t Val_Loss: 0.2485316265374422\nEpoch:  19\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:57<00:00,  1.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 0.09404068134725094\t Accuracy: 81.91015625\t Val_Accuracy: 45.458984375\t Val_Loss: 0.24659836292266846\nEpoch:  20\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:57<00:00,  1.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 0.08966718707233667\t Accuracy: 83.40625\t Val_Accuracy: 45.1171875\t Val_Loss: 0.22029443085193634\nTest_Accuracy 39.208984375\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.022 MB of 0.022 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Accuracy</td><td>▁▁▁▂▂▃▄▅▅▅▆▆▆▇▇▇▇███</td></tr><tr><td>Epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>Loss</td><td>█▇▆▄▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Val_Accuracy</td><td>▁▁▁▃▄▅▆▆▇▇▇▇▇███████</td></tr><tr><td>Val_Loss</td><td>█▇▅▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Accuracy</td><td>83.40625</td></tr><tr><td>Epoch</td><td>20</td></tr><tr><td>Loss</td><td>0.08967</td></tr><tr><td>Val_Accuracy</td><td>45.11719</td></tr><tr><td>Val_Loss</td><td>0.22029</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">skilled-sweep-1</strong> at: <a href='https://wandb.ai/cs23m063/deep_learn_assignment_3/runs/4tet7lum' target=\"_blank\">https://wandb.ai/cs23m063/deep_learn_assignment_3/runs/4tet7lum</a><br/> View project at: <a href='https://wandb.ai/cs23m063/deep_learn_assignment_3' target=\"_blank\">https://wandb.ai/cs23m063/deep_learn_assignment_3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240515_182706-4tet7lum/logs</code>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}