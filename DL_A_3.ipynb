{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8375982,"sourceType":"datasetVersion","datasetId":4980280}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install wandb\nimport numpy as np\nimport pandas as pd\nimport wandb\nimport random\nimport torch\nimport torch.nn as nn\nfrom torch import optim\nimport torch.nn.functional as F\nfrom tqdm import tqdm\nwandb.login()\nimport csv\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-13T13:15:25.435512Z","iopub.execute_input":"2024-05-13T13:15:25.436468Z","iopub.status.idle":"2024-05-13T13:15:53.721795Z","shell.execute_reply.started":"2024-05-13T13:15:25.436433Z","shell.execute_reply":"2024-05-13T13:15:53.720769Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.16.6)\nRequirement already satisfied: Click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.7)\nRequirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.41)\nRequirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.31.0)\nRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.45.0)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0.1)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (69.0.3)\nRequirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.4.4)\nRequirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\nRequirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"}]},{"cell_type":"code","source":"def read_and_split_data(train_file, test_file, val_file):\n    # Read data\n    train_data = pd.read_csv(train_file, header=None)\n    test_data = pd.read_csv(test_file, header=None)\n    val_data = pd.read_csv(val_file, header=None)\n\n    # Split into English and Marathi words\n    english_train = train_data.iloc[:, 0]\n    marathi_train = train_data.iloc[:, 1]\n\n    english_test = test_data.iloc[:, 0]\n    marathi_test = test_data.iloc[:, 1]\n\n    english_val = val_data.iloc[:, 0]\n    marathi_val = val_data.iloc[:, 1]\n\n    return (english_train, marathi_train, english_test, marathi_test, english_val, marathi_val)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-05-13T13:15:53.725301Z","iopub.execute_input":"2024-05-13T13:15:53.725750Z","iopub.status.idle":"2024-05-13T13:15:53.732200Z","shell.execute_reply.started":"2024-05-13T13:15:53.725725Z","shell.execute_reply":"2024-05-13T13:15:53.731338Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# File paths\nlang=\"mar\"\ntrain_file = f\"/kaggle/input/aksharantar-sampled/aksharantar_sampled/{lang}/{lang}_train.csv\"\ntest_file = f\"/kaggle/input/aksharantar-sampled/aksharantar_sampled/{lang}/{lang}_test.csv\"\nval_file = f\"/kaggle/input/aksharantar-sampled/aksharantar_sampled/{lang}/{lang}_valid.csv\"\n\n# Call the function\nenglish_train, marathi_train, english_test, marathi_test, english_val, marathi_val = read_and_split_data(train_file, test_file, val_file)","metadata":{"execution":{"iopub.status.busy":"2024-05-13T13:15:53.733559Z","iopub.execute_input":"2024-05-13T13:15:53.734184Z","iopub.status.idle":"2024-05-13T13:15:53.896044Z","shell.execute_reply.started":"2024-05-13T13:15:53.734153Z","shell.execute_reply":"2024-05-13T13:15:53.895264Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def create_char_list(words):\n    char_set = set(char for word in words for char in word)\n    char_list = sorted(char_set)\n    max_length_word = max(len(word) for word in words)\n    return char_list, max_length_word\n\n\ndef find_max_length(word_list):\n    max_length = -1\n    for word in word_list:\n        max_length = max(max_length, len(word))\n    return max_length\n\n# Create character lists and find maximum word lengths\nenglish_chars, english_max_len = create_char_list(english_train)\nmarathi_chars, marathi_max_len = create_char_list(marathi_train)\n\n# Find maximum word lengths from validation and test data\nenglish_max_len = max(find_max_length(english_val), find_max_length(english_test), english_max_len)\nmarathi_max_len = max(find_max_length(marathi_val), find_max_length(marathi_test), marathi_max_len)","metadata":{"execution":{"iopub.status.busy":"2024-05-13T13:15:53.898179Z","iopub.execute_input":"2024-05-13T13:15:53.898493Z","iopub.status.idle":"2024-05-13T13:15:54.030582Z","shell.execute_reply.started":"2024-05-13T13:15:53.898470Z","shell.execute_reply":"2024-05-13T13:15:54.029829Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def word_to_vector(word, lang):\n    max_len = -1\n    if lang == \"english\":\n        max_len = english_max_len\n    else:\n        max_len = marathi_max_len\n\n    vector = [0] * (max_len + 2)  # Initialize vector with max length + 2 (for special tokens)\n    vector[0] = len(english_chars) + 1 if lang == \"english\" else len(marathi_chars) + 1\n    count=1\n    if(lang == \"english\"):\n        for char in word:\n            for i in range(len(english_chars)):\n                if(english_chars[i] == char):\n                    vector[count]=i+1\n                    count+=1\n    else :\n        for char in word:\n            for i in range(len(marathi_chars)):\n                if(marathi_chars[i] == char):\n                    vector[count]=i+1\n                    count+=1\n\n    return vector\n","metadata":{"execution":{"iopub.status.busy":"2024-05-13T13:15:54.031752Z","iopub.execute_input":"2024-05-13T13:15:54.031994Z","iopub.status.idle":"2024-05-13T13:15:54.039241Z","shell.execute_reply.started":"2024-05-13T13:15:54.031974Z","shell.execute_reply":"2024-05-13T13:15:54.038389Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def indices_to_words(indices, language):\n    words = []\n    char_list = english_chars if language == \"english\" else marathi_chars\n    for idx in range(len(indices)):\n        if idx == 0:\n            continue\n        if indices[idx]==0:\n            break\n        char = char_list[indices[idx] - 1]  # Adjust for zero-indexing\n        words.append(char)\n    return ''.join(words)","metadata":{"execution":{"iopub.status.busy":"2024-05-13T13:15:54.040500Z","iopub.execute_input":"2024-05-13T13:15:54.040790Z","iopub.status.idle":"2024-05-13T13:15:54.049985Z","shell.execute_reply.started":"2024-05-13T13:15:54.040768Z","shell.execute_reply":"2024-05-13T13:15:54.049131Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# creating matrix of representation\ndef word_matrix(words, language):\n    matrix = []\n    for word in words:\n        matrix.append(word_to_vector(word, language))\n    return torch.tensor(matrix)","metadata":{"execution":{"iopub.status.busy":"2024-05-13T13:15:54.050895Z","iopub.execute_input":"2024-05-13T13:15:54.051150Z","iopub.status.idle":"2024-05-13T13:15:54.061133Z","shell.execute_reply.started":"2024-05-13T13:15:54.051128Z","shell.execute_reply":"2024-05-13T13:15:54.060463Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def prepare_word_matrices(train_data, val_data, test_data, language):\n    train_matrix = word_matrix(train_data, language)\n    val_matrix = word_matrix(val_data, language)\n    test_matrix = word_matrix(test_data, language)\n    return train_matrix, val_matrix, test_matrix","metadata":{"execution":{"iopub.status.busy":"2024-05-13T13:15:54.062268Z","iopub.execute_input":"2024-05-13T13:15:54.062609Z","iopub.status.idle":"2024-05-13T13:15:54.074942Z","shell.execute_reply.started":"2024-05-13T13:15:54.062580Z","shell.execute_reply":"2024-05-13T13:15:54.074087Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"english_matrix, english_matrix_val, english_matrix_test = prepare_word_matrices(english_train, english_val, english_test, \"english\")\nmarathi_matrix, marathi_matrix_val, marathi_matrix_test = prepare_word_matrices(marathi_train, marathi_val, marathi_test, \"marathi\")","metadata":{"execution":{"iopub.status.busy":"2024-05-13T13:15:54.075943Z","iopub.execute_input":"2024-05-13T13:15:54.076227Z","iopub.status.idle":"2024-05-13T13:16:01.355242Z","shell.execute_reply.started":"2024-05-13T13:15:54.076193Z","shell.execute_reply":"2024-05-13T13:16:01.354256Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class Encoder(nn.Module):\n    def __init__(self, input_size, embedding_dim, hidden_size, num_layers, batch_size, dropout_prob, bidirectional, cell_type):\n        super(Encoder, self).__init__()\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        self.batch_size = batch_size\n        self.dropout = nn.Dropout(dropout_prob)\n        self.biderectional = bidirectional\n        self.embedding_dim = embedding_dim\n        self.embedding = nn.Embedding(input_size, embedding_dim)\n        self.cell_type = cell_type\n\n        rnn_class = nn.RNN if cell_type == \"RNN\" else (nn.LSTM if cell_type == \"LSTM\" else nn.GRU)\n        self.rnn = rnn_class(embedding_dim, hidden_size, num_layers, dropout=dropout_prob, bidirectional=bidirectional)\n\n    def forward(self, input):\n        embedded = self.dropout(self.embedding(input))\n        if self.cell_type == \"LSTM\":\n            output, (hidden, cell) = self.rnn(embedded)\n        else:\n            output, hidden = self.rnn(embedded)\n\n        return (output, hidden, cell) if self.cell_type == \"LSTM\" else (output, hidden)\n\n    def init_hidden(self):\n        return torch.zeros(1, 1, self.hidden_size, device=device)","metadata":{"execution":{"iopub.status.busy":"2024-05-13T13:16:01.359259Z","iopub.execute_input":"2024-05-13T13:16:01.359554Z","iopub.status.idle":"2024-05-13T13:16:01.369156Z","shell.execute_reply.started":"2024-05-13T13:16:01.359530Z","shell.execute_reply":"2024-05-13T13:16:01.368170Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"class Decoder(nn.Module):\n    def __init__(self, input_size, embedding_size, hidden_size, output_size, dec_layers, p, cell_type, attention=False, bidirectional=False):\n        super(Decoder, self).__init__()\n        self.hidden_size = hidden_size\n        self.output_size = output_size\n        self.dec_layers = dec_layers\n        self.dropout = nn.Dropout(p)\n        self.cell_type = cell_type\n        self.attention = attention\n        self.bidirectional = bidirectional\n        self.max_length = len(english_matrix[0])\n\n        self.embedding = nn.Embedding(input_size, embedding_size)\n        rnn_input_size = hidden_size if attention else embedding_size\n        rnn_class = nn.RNN if cell_type == \"RNN\" else (nn.LSTM if cell_type == \"LSTM\" else nn.GRU)\n        self.rnn = rnn_class(rnn_input_size, hidden_size, dec_layers, dropout=p)\n        self.fc = nn.Linear(hidden_size, output_size)\n\n        if attention:\n            self.attn = nn.Linear(hidden_size + embedding_size, self.max_length)\n            self.attn_combine = nn.Linear(hidden_size * 2 + embedding_size, hidden_size) if bidirectional else nn.Linear(hidden_size + embedding_size, hidden_size)\n\n    def forward(self, x, output, hidden, cell=None):\n        x = x.unsqueeze(0)\n        embedded = self.embedding(x)\n        embedded = self.dropout(embedded)\n\n        if self.attention:\n            attn_weights = F.softmax(self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n            attn_applied = torch.bmm(attn_weights.unsqueeze(1), output.permute(1, 0, 2)).squeeze(1)\n            op = torch.cat((embedded[0], attn_applied), 1)\n            op = self.attn_combine(op).unsqueeze(0)\n            op = F.relu(op)\n        else:\n            op = embedded\n\n        if self.cell_type == \"LSTM\":\n            outputs, (hidden, cell) = self.rnn(op, (hidden, cell))\n        else:\n            outputs, hidden = self.rnn(op, hidden)\n\n        predictions, hidden, cell = self.generate_predictions(outputs, hidden, cell)\n\n        return predictions, hidden, cell\n\n    def generate_predictions(self, rnn_outputs, rnn_hidden, rnn_cell=None):\n        output_predictions = self.fc(rnn_outputs)\n        output_predictions = output_predictions.squeeze(0)\n\n        return (output_predictions, rnn_hidden, rnn_cell) if self.cell_type == \"LSTM\" else (output_predictions, rnn_hidden ,rnn_cell)\n\n\n    def initHidden(self):\n        return torch.zeros(1, 1, self.hidden_size, device=device)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-13T13:16:01.370382Z","iopub.execute_input":"2024-05-13T13:16:01.370703Z","iopub.status.idle":"2024-05-13T13:16:01.386197Z","shell.execute_reply.started":"2024-05-13T13:16:01.370678Z","shell.execute_reply":"2024-05-13T13:16:01.385380Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"class Seq2SeqModel(nn.Module):\n    def __init__(self, output_size, cell_type, bidirectional, enc_layers, dec_layers, encoder, decoder):\n        super(Seq2SeqModel, self).__init__()\n        self.output_size = output_size\n        self.cell_type = cell_type\n        self.bidirectional = bidirectional\n        self.enc_layers = enc_layers\n        self.dec_layers = dec_layers\n        self.encoder = encoder\n        self.decoder = decoder\n\n    def forward(self, source, target , teacher_force_ratio=0.5):\n        target_len = target.shape[0]\n        batch_size = source.shape[1]\n\n        outputs = torch.zeros(target_len, batch_size, self.output_size).to(source.device)\n\n        encoder_output, hidden, cell = self.encode_sequence(source)\n        hidden, cell = self.prepare_decoder_states(hidden, cell)\n        outputs = self.decode_sequence(target, encoder_output, hidden, cell, teacher_force_ratio)\n\n        return outputs\n\n    def encode_sequence(self, source):\n        if self.cell_type == \"LSTM\":\n            encoder_output, hidden, cell = self.encoder(source)\n            return encoder_output, hidden, cell\n        else:\n            encoder_output, hidden = self.encoder(source)\n            return encoder_output, hidden, None\n\n    def prepare_decoder_states(self, hidden, cell):\n        if self.bidirectional or self.enc_layers != self.dec_layers:\n          hidden = hidden[self.enc_layers - 1] + hidden[self.enc_layers - 1]\n          hidden = hidden.repeat(self.dec_layers,1,1)\n          if(self.cell_type == \"LSTM\"):\n              cell = cell[self.enc_layers - 1] + cell[self.enc_layers - 1]\n              cell = cell.repeat(self.dec_layers,1,1)\n        return hidden, cell\n\n\n    def decode_sequence(self, tgt, enc_out, hid, cell, teacher_force_ratio):\n        batch_size = tgt.shape[1]\n        target_len = tgt.shape[0]\n        outputs = torch.zeros(target_len, batch_size, self.output_size).to(enc_out.device)\n\n        timestep = 1\n        current_token = tgt[0]\n\n        while timestep < target_len:\n            if self.cell_type == \"LSTM\":\n                output, hid, cell = self.decoder(current_token, enc_out, hid, cell)\n            else:\n                output, hid, cell = self.decoder(current_token, enc_out, hid)\n            outputs[timestep] = output\n\n            if random.random() < teacher_force_ratio:\n                current_token = tgt[timestep] if timestep < target_len - 1 else output.argmax(1)\n            else:\n                current_token = output.argmax(1)\n\n            timestep += 1\n\n        return outputs","metadata":{"execution":{"iopub.status.busy":"2024-05-13T13:16:01.387347Z","iopub.execute_input":"2024-05-13T13:16:01.387885Z","iopub.status.idle":"2024-05-13T13:16:01.402685Z","shell.execute_reply.started":"2024-05-13T13:16:01.387861Z","shell.execute_reply":"2024-05-13T13:16:01.401870Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def calculate_accuracy_test(model, input_data, target_data, batch_size):\n    correct_count = 0\n    total_samples = len(input_data)\n    predicted_words=[]\n    for idx in range(0, total_samples, batch_size):\n        input_batch = input_data[idx:idx + batch_size].to(device)\n        target_batch = target_data[idx:idx + batch_size].to(device)\n\n        output = model(input_batch.T, target_batch.T, teacher_force_ratio=0)\n        predicted_tokens = torch.argmax(F.softmax(output, dim=2), dim=2).T\n        \n        for tokens in predicted_tokens:\n            predicted_word = indices_to_words(tokens, \"marathi\")\n            predicted_words.append(predicted_word)\n            \n        correct_count += torch.all(predicted_tokens[:, 1:] == target_batch[:, 1:], dim=1).sum().item()\n        \n    accuracy = correct_count * 100 / total_samples\n    return accuracy,predicted_words\n","metadata":{"execution":{"iopub.status.busy":"2024-05-13T13:16:01.403789Z","iopub.execute_input":"2024-05-13T13:16:01.404164Z","iopub.status.idle":"2024-05-13T13:16:01.417347Z","shell.execute_reply.started":"2024-05-13T13:16:01.404131Z","shell.execute_reply":"2024-05-13T13:16:01.416549Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def calculate_accuracy(model, input_data, target_data, batch_size):\n    correct_count = 0\n    total_samples = len(input_data)\n    for idx in range(0, total_samples, batch_size):\n        input_batch = input_data[idx:idx + batch_size].to(device)\n        target_batch = target_data[idx:idx + batch_size].to(device)\n\n        output = model(input_batch.T, target_batch.T, teacher_force_ratio=0)\n        predicted_tokens = torch.argmax(F.softmax(output, dim=2), dim=2).T\n            \n        correct_count += torch.all(predicted_tokens[:, 1:] == target_batch[:, 1:], dim=1).sum().item()\n        \n    accuracy = correct_count * 100 / total_samples\n    return accuracy\n","metadata":{"execution":{"iopub.status.busy":"2024-05-13T13:16:01.418234Z","iopub.execute_input":"2024-05-13T13:16:01.418522Z","iopub.status.idle":"2024-05-13T13:16:01.427250Z","shell.execute_reply.started":"2024-05-13T13:16:01.418496Z","shell.execute_reply":"2024-05-13T13:16:01.426463Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def write_to_csv(actual_english, actual_marathi, predicted_marathi, filename):\n    with open(filename, mode='w', newline='', encoding='utf-8') as file:\n        writer = csv.writer(file)\n        writer.writerow(['Actual English', 'Actual Marathi', 'Predicted Marathi'])\n        for eng, mar_actual, mar_pred in zip(actual_english, actual_marathi, predicted_marathi):\n            writer.writerow([eng, mar_actual, mar_pred])\n","metadata":{"execution":{"iopub.status.busy":"2024-05-13T13:16:01.428290Z","iopub.execute_input":"2024-05-13T13:16:01.428748Z","iopub.status.idle":"2024-05-13T13:16:01.440722Z","shell.execute_reply.started":"2024-05-13T13:16:01.428719Z","shell.execute_reply":"2024-05-13T13:16:01.439995Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def train_model(epochs, learning_rate, cell_type, bidirectional, enc_layers, dec_layers, batch_size, embedding_dim, hidden_size, enc_dropout, dec_dropout,attention):\n    pad_idx = len(marathi_chars) + 1\n\n    input_size_encoder = len(english_chars)\n    input_size_decoder = len(marathi_chars)\n    output_size = len(marathi_chars)\n    input_size_encoder+=2\n    input_size_decoder+=2\n    output_size+=2\n\n    encoder = Encoder(input_size_encoder, embedding_dim, hidden_size, enc_layers,batch_size, enc_dropout,bidirectional, cell_type).to(device)\n    decoder= Decoder(input_size_decoder,embedding_dim,hidden_size,output_size,dec_layers,dec_dropout, cell_type,attention,bidirectional).to(device)\n\n    model = Seq2SeqModel(output_size, cell_type, bidirectional, enc_layers, dec_layers ,encoder, decoder).to(device)\n    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n    criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n\n    for epoch in range(epochs):\n        print(\"Epoch: \", epoch+1)\n\n        model.train()\n        total_loss = 0\n        val_loss = 0\n        step = 0\n        total_batches = len(english_matrix) // batch_size\n\n        for batch_idx in tqdm(range(total_batches)):\n            start_idx = batch_size * batch_idx\n            end_idx = batch_size * (batch_idx + 1)\n\n            inp_data = english_matrix[start_idx:end_idx].to(device)\n            target = marathi_matrix[start_idx:end_idx].to(device)\n            target = target.T\n\n            optimizer.zero_grad()\n            output = model(inp_data.T, target)\n\n            output = output[1:].reshape(-1, output.shape[2])\n            target = target[1:].reshape(-1)\n\n            loss = criterion(output, target)\n            total_loss += loss.item()\n            loss.backward()\n\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n\n            optimizer.step()\n\n            step += 1\n\n        with torch.no_grad():\n            model.eval()\n            val_batches = len(english_matrix_val) // batch_size\n            for val_batch_idx in range(val_batches):\n                val_start_idx = batch_size * val_batch_idx\n                val_end_idx = batch_size * (val_batch_idx + 1)\n\n                val_inp_data = english_matrix_val[val_start_idx:val_end_idx].to(device)\n                val_target = marathi_matrix_val[val_start_idx:val_end_idx].to(device)\n                val_target = val_target.T\n\n                val_output = model(val_inp_data.T, val_target)\n                val_output = val_output[1:].reshape(-1, val_output.shape[2])\n                val_target = val_target[1:].reshape(-1)\n\n                val_loss += criterion(val_output, val_target).item()\n\n            val_loss /= val_batches\n        training_accuracy = calculate_accuracy(model, english_matrix, marathi_matrix, batch_size)\n        val_accuracy = calculate_accuracy(model, english_matrix_val, marathi_matrix_val, batch_size)\n        wandb.log({\n            \"Epoch\": epoch+1,\n            \"Loss\": total_loss / step,\n            \"Accuracy\": training_accuracy,\n            \"Val_Accuracy\": val_accuracy,\n            \"Val_Loss\": val_loss\n        })\n        print(f\"Loss: {total_loss/step}\\t Accuracy: {training_accuracy}\\t Val_Accuracy: {val_accuracy}\\t Val_Loss: {val_loss}\")\n    test_accuracy,predicted_words=calculate_accuracy_test(model, english_matrix_test, marathi_matrix_test, batch_size)\n    wandb.log({\"Test_Accuracy_Attention\":test_accuracy})\n    print(f\"Test_Accuracy_Attention = {test_accuracy}\")\n    write_to_csv(english_test, marathi_test, predicted_words, '/kaggle/working/predictions.csv')    ","metadata":{"execution":{"iopub.status.busy":"2024-05-13T13:16:01.441974Z","iopub.execute_input":"2024-05-13T13:16:01.442296Z","iopub.status.idle":"2024-05-13T13:16:01.460965Z","shell.execute_reply.started":"2024-05-13T13:16:01.442273Z","shell.execute_reply":"2024-05-13T13:16:01.460096Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Define the sweep configuration\nsweep_config = {\n    \"method\": \"bayes\",\n    'metric': {\n        'name': 'Val_Accuracy',\n        'goal': 'maximize'\n    },\n    \"parameters\": {\n        \"epochs\": {\"values\": [15]},  # Define the hyperparameter search space\n        \"learning_rate\": {\"values\": [1e-3]},\n        \"cell_type\": {\"values\": [\"LSTM\"]},\n        \"bidirectional\": {\"values\": [True]},\n        \"enc_layers\": {\"values\": [1]},\n        \"dec_layers\": {\"values\": [1]},\n        \"batch_size\": {\"values\": [256]},\n        \"embedding_dim\": {\"values\": [512]},\n        \"hidden_size\": {\"values\": [384]},\n        \"enc_dropout\": {\"values\": [0.2]},\n        \"dec_dropout\": {\"values\": [0.1]},\n        \"attention\": {\"values\": [True]}\n    }\n}","metadata":{"execution":{"iopub.status.busy":"2024-05-13T13:16:01.462020Z","iopub.execute_input":"2024-05-13T13:16:01.462309Z","iopub.status.idle":"2024-05-13T13:16:01.475583Z","shell.execute_reply.started":"2024-05-13T13:16:01.462287Z","shell.execute_reply":"2024-05-13T13:16:01.474715Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def main():\n    # Initialize wandb\n    wandb.init()\n    config = wandb.config\n    wandb.run.name = \"_\".join([f\"{param}:{value}\" for param, value in config.items()])\n    train_model(**config)\n\n# Initialize the sweep\nsweep_id = wandb.sweep(sweep_config, project=\"deep_learn_assignment_3\",entity=\"cs23m063\")\n\n# Run the sweep\nwandb.agent(sweep_id, function=main,count=1)","metadata":{"execution":{"iopub.status.busy":"2024-05-13T13:16:01.476528Z","iopub.execute_input":"2024-05-13T13:16:01.476782Z","iopub.status.idle":"2024-05-13T13:22:03.849461Z","shell.execute_reply.started":"2024-05-13T13:16:01.476753Z","shell.execute_reply":"2024-05-13T13:22:03.848760Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Create sweep with ID: e6lbyd2m\nSweep URL: https://wandb.ai/cs23m063/deep_learn_assignment_3/sweeps/e6lbyd2m\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: vvtdh99r with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tattention: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_dropout: 0.1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_dim: 512\n\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_dropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 15\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 384\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcs23m063\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240513_131603-vvtdh99r</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs23m063/deep_learn_assignment_3/runs/vvtdh99r' target=\"_blank\">leafy-sweep-1</a></strong> to <a href='https://wandb.ai/cs23m063/deep_learn_assignment_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs23m063/deep_learn_assignment_3/sweeps/e6lbyd2m' target=\"_blank\">https://wandb.ai/cs23m063/deep_learn_assignment_3/sweeps/e6lbyd2m</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs23m063/deep_learn_assignment_3' target=\"_blank\">https://wandb.ai/cs23m063/deep_learn_assignment_3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs23m063/deep_learn_assignment_3/sweeps/e6lbyd2m' target=\"_blank\">https://wandb.ai/cs23m063/deep_learn_assignment_3/sweeps/e6lbyd2m</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs23m063/deep_learn_assignment_3/runs/vvtdh99r' target=\"_blank\">https://wandb.ai/cs23m063/deep_learn_assignment_3/runs/vvtdh99r</a>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n  warnings.warn(\"dropout option adds dropout after all but last \"\n/opt/conda/lib/python3.10/site-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n  warnings.warn(\"dropout option adds dropout after all but last \"\n","output_type":"stream"},{"name":"stdout","text":"Epoch:  1\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 200/200 [00:16<00:00, 12.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 1.1620930571854116\t Accuracy: 13.1015625\t Val_Accuracy: 13.818359375\t Val_Loss: 0.42545054480433464\nEpoch:  2\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 200/200 [00:15<00:00, 12.97it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 0.39389967039227486\t Accuracy: 30.232421875\t Val_Accuracy: 28.076171875\t Val_Loss: 0.2865810450166464\nEpoch:  3\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 200/200 [00:15<00:00, 12.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 0.27624174661934375\t Accuracy: 40.90625\t Val_Accuracy: 34.8876953125\t Val_Loss: 0.24545917473733425\nEpoch:  4\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 200/200 [00:16<00:00, 12.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 0.22588990472257137\t Accuracy: 46.384765625\t Val_Accuracy: 36.71875\t Val_Loss: 0.2569971838966012\nEpoch:  5\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 200/200 [00:16<00:00, 12.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 0.19586514294147492\t Accuracy: 49.30859375\t Val_Accuracy: 37.9638671875\t Val_Loss: 0.23181634861975908\nEpoch:  6\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 200/200 [00:16<00:00, 12.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 0.17363558892160655\t Accuracy: 53.20703125\t Val_Accuracy: 40.91796875\t Val_Loss: 0.2229575589299202\nEpoch:  7\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 200/200 [00:16<00:00, 12.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 0.15566334325820208\t Accuracy: 58.310546875\t Val_Accuracy: 42.1630859375\t Val_Loss: 0.22545903082937002\nEpoch:  8\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 200/200 [00:16<00:00, 12.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 0.14601604644209146\t Accuracy: 60.92578125\t Val_Accuracy: 42.919921875\t Val_Loss: 0.21415663417428732\nEpoch:  9\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 200/200 [00:16<00:00, 12.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 0.13037221353501083\t Accuracy: 62.71875\t Val_Accuracy: 43.26171875\t Val_Loss: 0.21943324711173773\nEpoch:  10\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 200/200 [00:16<00:00, 12.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 0.11920485649257899\t Accuracy: 65.79296875\t Val_Accuracy: 45.849609375\t Val_Loss: 0.22151593584567308\nEpoch:  11\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 200/200 [00:16<00:00, 12.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 0.11881094478070736\t Accuracy: 66.455078125\t Val_Accuracy: 45.0927734375\t Val_Loss: 0.2402782216668129\nEpoch:  12\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 200/200 [00:16<00:00, 12.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 0.10831052921712399\t Accuracy: 65.8359375\t Val_Accuracy: 44.580078125\t Val_Loss: 0.21053084824234247\nEpoch:  13\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 200/200 [00:16<00:00, 12.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 0.10027203606441618\t Accuracy: 72.32421875\t Val_Accuracy: 47.0458984375\t Val_Loss: 0.2166393892839551\nEpoch:  14\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 200/200 [00:16<00:00, 12.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 0.08905620243400335\t Accuracy: 73.935546875\t Val_Accuracy: 46.7529296875\t Val_Loss: 0.2210965408012271\nEpoch:  15\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 200/200 [00:16<00:00, 12.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 0.0835266475006938\t Accuracy: 75.62109375\t Val_Accuracy: 47.4365234375\t Val_Loss: 0.2262528920546174\nTest_Accuracy_Attention = 41.7724609375\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Accuracy</td><td>▁▃▄▅▅▅▆▆▇▇▇▇███</td></tr><tr><td>Epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>Loss</td><td>█▃▂▂▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Test_Accuracy_Attention</td><td>▁</td></tr><tr><td>Val_Accuracy</td><td>▁▄▅▆▆▇▇▇▇██▇███</td></tr><tr><td>Val_Loss</td><td>█▃▂▃▂▁▁▁▁▁▂▁▁▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Accuracy</td><td>75.62109</td></tr><tr><td>Epoch</td><td>15</td></tr><tr><td>Loss</td><td>0.08353</td></tr><tr><td>Test_Accuracy_Attention</td><td>41.77246</td></tr><tr><td>Val_Accuracy</td><td>47.43652</td></tr><tr><td>Val_Loss</td><td>0.22625</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">leafy-sweep-1</strong> at: <a href='https://wandb.ai/cs23m063/deep_learn_assignment_3/runs/vvtdh99r' target=\"_blank\">https://wandb.ai/cs23m063/deep_learn_assignment_3/runs/vvtdh99r</a><br/> View project at: <a href='https://wandb.ai/cs23m063/deep_learn_assignment_3' target=\"_blank\">https://wandb.ai/cs23m063/deep_learn_assignment_3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240513_131603-vvtdh99r/logs</code>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}